---
title: "Simulation of bias and coverage"
author: "Lars BÃ¸rty Nielsen"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulation of bias and coverage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


The ccostr package includes a function to simulate data. We can use this to test the accaracy of the estimates and confidence intervals.
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(ccostr)
library(ggplot2)
library(knitr)
library(parallel)
library(msm)
```


In the simulated data the cost function takes the following form:

$$M_i = M_i(0)+b_iT_i^L+\sum^{10}_{j=1}\tau_{ij}(min[\{T_i^L-(j-1)\}^+,1])+d_iI(T_i\leq10)$$

With a uniform distribution of survival times this is set to take the value of 40.000, we can now test the estimators:
```{r}
sim <- simCostData(n = 1000, dist = "unif", censor = "light", cdist = "exp", L = 10)

est <- ccmean(sim$censoredCostHistory)
est
```

We can plot this with a line for the true value
```{r fig.height=3, fig.width=7}
plot(est) + geom_hline(yintercept = 40000, linetype = "dotted", size = 1)
```


We can now test the bias of the estimators and their coverage with the simulated data. We use parralization to speed up the process with a higher number of simulations/individuals, but it should be adjusted to fit the used computer. First the data is simulated:
```{r }
nSim   <- 10
nYears <- 10
indv   <- 100 # increating individuals increases computing time exponential

## true mean for unif is 40000 and exp is 35956
cdist = "exp"
unif_light <- lapply(1:nSim, function(x) simCostData(n = indv, dist = "unif", censor = "light", cdist = "exp", L = nYears))
unif_heavy <- lapply(1:nSim, function(x) simCostData(n = indv, dist = "unif", censor = "heavy", cdist = "exp", L = nYears))
exp_light  <- lapply(1:nSim, function(x) simCostData(n = indv, dist = "exp",  censor = "light", cdist = "exp", L = nYears))
exp_heavy  <- lapply(1:nSim, function(x) simCostData(n = indv, dist = "exp",  censor = "heavy", cdist = "exp", L = nYears))
```

Then the data is sent to the cluster and the estimates are calculated:
```{r}
nCores <- 2
cl <- makeCluster(nCores)
clusterExport(cl = cl, c("unif_light", "unif_heavy", "exp_light", "exp_heavy"))
invisible(clusterEvalQ(cl = cl, {library(dplyr)
                                 library(ccostr)
                                 library(data.table)
                                 library(survival)}))
est_unif_light <- parLapply(cl, unif_light, function(x) ccmean(x$censoredCostHistory, L = 10))
est_unif_heavy <- parLapply(cl, unif_heavy, function(x) ccmean(x$censoredCostHistory, L = 10))
est_exp_light  <- parLapply(cl, exp_light,  function(x) ccmean(x$censoredCostHistory, L = 10))
est_exp_heavy  <- parLapply(cl, exp_heavy,  function(x) ccmean(x$censoredCostHistory, L = 10))
stopCluster(cl)
```


### Results
Now the results are pasted together to a table:
```{r}
results_unif_light <- do.call(rbind, lapply(est_unif_light, function(x) x[[3]]))
results_unif_heavy <- do.call(rbind, lapply(est_unif_heavy, function(x) x[[3]]))
results_exp_light  <- do.call(rbind, lapply(est_exp_light,  function(x) x[[3]]))
results_exp_heavy  <- do.call(rbind, lapply(est_exp_heavy,  function(x) x[[3]]))

results_true <- data.frame("unif_light" = 40000,
                           "unif_heavy" = 40000,
                           "exp_light"  = 35956,
                           "exp_heavy"  = 35956)

results_mean <- data.frame("unif_light" = mean(sapply(unif_light, function(x) mean(x$totalCost))),
                           "unif_heavy" = mean(sapply(unif_heavy, function(x) mean(x$totalCost))),
                           "exp_light"  = mean(sapply(exp_light, function(x) mean(x$totalCost))),
                           "exp_heavy"  = mean(sapply(exp_heavy, function(x) mean(x$totalCost))))

results_bias <- data.frame("unif_light" = (colMeans(results_unif_light)),
                           "unif_heavy" = (colMeans(results_unif_heavy)),
                           "exp_light"  = (colMeans(results_exp_light)),
                           "exp_heavy"  = (colMeans(results_exp_heavy)))

results <- rbind(results_true, results_mean, results_bias)
row.names(results) <- c("true_mean", "simulation_mean", colnames(results_unif_light))
kable(results)
```

### Bias
```{r}
results_bias <- cbind(round(results[,c(1,2)] - 40000,2), 
                      round(results[,c(3,4)] - 35956,2))
kable(results_bias)
```

It seems there is more bias in the ZT estimator, this might have to do with the implementation of the simulation

### Coverage
```{r}
cov_unif_light <- do.call(rbind, lapply(est_unif_light, function(x) ifelse(x[[4]][4,] >= 40000 & x[[4]][5,] <= 40000, 1, 0)))
cov_unif_heavy <- do.call(rbind, lapply(est_unif_heavy, function(x) ifelse(x[[4]][4,] >= 40000 & x[[4]][5,] <= 40000, 1, 0)))
cov_exp_light  <- do.call(rbind, lapply(est_exp_light,  function(x) ifelse(x[[4]][4,] >= 35956 & x[[4]][5,] <= 35956, 1, 0)))
cov_exp_heavy  <- do.call(rbind, lapply(est_exp_heavy,  function(x) ifelse(x[[4]][4,] >= 35956 & x[[4]][5,] <= 35956, 1, 0)))

results_coverage <- data.frame("unif_light" = (colMeans(cov_unif_light, na.rm = T)),
                               "unif_heavy" = (colMeans(cov_unif_heavy, na.rm = T)),
                               "exp_light"  = (colMeans(cov_exp_light,  na.rm = T)),
                               "exp_heavy"  = (colMeans(cov_exp_heavy,  na.rm = T)))
kable(results_coverage, digits = 3)
```

As can be seen the coverage ratios looks very close to the 95%















