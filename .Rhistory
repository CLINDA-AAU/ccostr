t$GB[i] <- (1 / (n*t$s.surv[i])) * sum(t2$delta * t2$cost / t2$sc.surv)
}
BT_var <- 1/n * (mean(t$delta*(t$cost-BT)^2/t$sc.surv) +
mean(((1-t$delta)/t$sc.surv^2 )* (t$GA - t$GB^2)))
BT_sd <- sqrt(BT_var)
BT_uci <- BT + (1.96 * BT_sd)
BT_lci <- BT - (1.96 * BT_sd)
BT_full <- c(BT, BT_var, BT_sd, BT_uci, BT_lci)
# END VAR BT --------------------------------------------------------------
#################################################################
##                          section 6:                         ##
##                Zhao and Tian's method (2001)                ##
#################################################################
## For each censored individual i calculate cost
## of longer surviving individuals up till time ti
runCostMatrix <- matrix(0, nrow = nrow(t), ncol = nrow(t))
t$mcostlsurv <- 0
t$mcostlsurvSq <- 0
for(i in 1:nrow(t)){
if(t$delta[i] == 1){
next
} else{
t_data2 <- subset(x, start <= t$surv[i])
t_data2$cost <- ifelse(t_data2$stop > t$surv[i],
(t_data2$cost/(t_data2$stop-t_data2$start + addInterPol))*
(t$surv[i]-t_data2$start +addInterPol),
t_data2$cost)
# summarized
t_data_total_temp <- t_data2 %>%
group_by(id) %>%
summarize(cost = sum(cost, na.rm=T),
surv= first(surv))
# Store in runCostMatrix for kept ids
idIndex <- t$id %in% t_data_total_temp$id
ids     <- t$id[idIndex]
runCost <- t_data_total_temp$cost
names(runCost) <- t_data_total_temp$id
runCostMatrix[idIndex,i] <- runCost[as.character(ids)]
# Get mean runCost for longer surviving ids
t$mcostlsurv[i]   <- mean(t_data_total_temp$cost[t_data_total_temp$surv >= t$surv[i]])
t$mcostlsurvSq[i] <- mean(t_data_total_temp$cost[t_data_total_temp$surv >= t$surv[i]]^2)
}
}
ZT <- mean((t$delta * (t$cost / t$sc.surv))) + mean(((1-t$delta) * ((t$cost-t$mcostlsurv) / t$sc.surv)), na.rm=T)
## Estimate variance
n <- nrow(t)
t$gm  <- rep(0,n)
t$gmm <- rep(0,n)
for(i in 1:n){
if(t$delta[i] == 1) next
t$gm[i]  <- (1/(n*t$s.surv[i])) * sum(as.numeric(t$surv >= t$surv[i]) * t$delta * runCostMatrix[,i] / t$sc.surv)
t$gmm[i] <- (1/(n*t$s.surv[i])) * sum(as.numeric(t$surv >= t$surv[i]) * t$delta * t$cost * runCostMatrix[,i] / t$sc.surv)
}
ztVAR <- BT_var - (2/n^2) * sum(((1-t$delta) /  t$sc.surv^2) * (t$gmm - t$GB * t$gm)) +
(1/n^2) * sum(((1-t$delta) /  t$sc.surv^2) * (t$mcostlsurvSq - t$mcostlsurv^2))
ZT_full <- c(ZT,
ztVAR,
sqrt(ztVAR),
ZT + 1.96 * sqrt(ztVAR),
ZT - 1.96 * sqrt(ztVAR))
#################################################################
##                          section 7:                         ##
##                           Results                           ##
#################################################################
results <- list("These results should be checked before ...",
data.frame(available_sample,
complete_case,
LinT,
BT,
ZT),
data.frame(available_sample_full,
complete_case_full,
LinT_full,
BT_full,
ZT_full,
row.names = c("Estimate", "Variance", "SD", "95UCI", "95LCI"))
)
return(results)
}
#' Sim
#'
#' @param annCost something
#' @return something
#' @export
#' @examples something
## function to summarize random annual cost
annCost <- function(T, tau, L){
cost <- 0
for(j in 1:min(L, ceiling(T))){
cost <- cost + min(T-(j-1), 1) * tau[j]
}
return(cost)
}
#' Sim
#'
#' @param totalCost something
#' @return something
#' @export
#' @examples something
## Function to calculate totalcost
totalCost <- function(T, M0, b, d, tau, L){
n <- length(T)
M <- c()
for(i in 1:n){
M[i] <-  M0[i] + b[i]*min(T[i],L) + d[i]*as.numeric(T[i] <= L)  + annCost(T[i], tau[,i], L)
}
return(M)
}
#' Simulates data for control of estimates of censored costs - LIN
#'
#' @param simCostData Simulates censored data
#' @return Different simulations
#' @export
#' @examples
#' simCostData(n = 100, dist = "unif", censor = "light", L = 10)
## Function to simulate cost data
## n is number of individuals to simulate
## dist is survival distribution either "unif" = unif(0,10) o r "exp" = exp (1/6)
## censor is "light" or "heavy" for unif(0,20) or unif(0,12.5)
## L is number of years to summarize over
simCostData <- function(n = 100, dist = "unif", censor = "light", L = 10){
## Simulate survival times
if(dist == "unif"){
T <- runif(n = n, min = 0, max = 10)
} else{
if(dist == "exp"){
T <- rexp(n = n, rate = 1/6)
} else{
stop('Dist must be "unif" or "exp"')
}
}
## Simulate censoring
if(censor == "light"){
C <- runif(n = n, min = 0, max = 20)
} else{
if(censor == "heavy"){
C <- runif(n = n, min = 0, max = 12.5)
} else{
stop('censor must be "light" or "heavy"')
}
}
## Simulate cost parameters
M0  <- runif(n = n, min = 5000,  max = 15000) # Initial Cost
b   <- runif(n = n, min = 1000,  max = 2600)  # Deterministic annual cost
d   <- runif(n = n, min = 10000, max = 30000) # Terminal cost
tau <- matrix(data = runif(n = n*ceiling(max(T)), min = 0, max = 400), ncol = n)   # Random annual cost
## Calculate total cost for individuals over L years
M <- totalCost(T, M0, b, d, tau, L)
## Calculate follow-up and censoring indicator
X <- pmin(T, C)
delta <- as.integer(T < C)
## Columns for dataframe with censored cost history
upperTime <- ceiling(X)
id    = rep(1:n, times = upperTime)
start = (unlist(sapply(upperTime, function(x) 1:x)) - 1)
stop  = unlist(sapply(upperTime, function(x) 1:x))
t     = rep(X, times = upperTime)
delta = rep(delta, times = upperTime)
stop  = pmin(stop, t)
## Calculate censored cost history in each interval / individual
cost <- 0
for(i in 1:length(id)){
cost[i] <- as.integer(start[i] == 0) * M0[id[i]] +      ## Initial cost if first interval
(stop[i] - start[i]) * b[id[i]] +                     ## Fixed annual cost
(stop[i] - start[i]) * tau[ceiling(stop[i]), id[i]] + ## Random annual cost
as.integer(t[i] == stop[i]) * delta[i] * d[id[i]]     ## Terminal cost if last interval and not censored
}
## Build output
results <- data.frame(id, start, stop, cost,"surv" = t, delta)
Mcens <- tapply(cost, id, sum)
return(list("totalCost" = M, "censoredCostHistory" = results))
}
#' Simulates data for control of estimates of censored costs - MARKOW
#'
#' Transition rate matrix for the illness-death model with recovery
#' State 1: No treatment; State 2: Treatment; State 3: Death; State 4: Censoring
#'
#'
#' @param sim.patients Simulates censored data
#' @return Different simulations
#' @export
#' @examples
#' sim.patients(n = 100, censor = 0.05, cost = 100)
sim.patients <- function(n, censor=0.05, cost){
lam12 <-  0.2
lam21 <-  0.5
lam13 <-  0.1
lam14 <- censor
lam23 <-  0.1
lam24 <- censor
qmatrix <- rbind(
c(   -1,    lam12,   lam13,  lam14),
c(lam21,       -1,   lam23,  lam24),
c(    0,        0,      -1,      0),
c(    0,        0,       0,     -1))
# Simulate n patients with transition rate matrix qmatrix and exponential
# cost/time-unit distribtion
xxx <- data.frame(id = character(), times = numeric(), state = numeric(), cost = numeric())
for(i in 1:n){
tmp <- sim.msm(qmatrix, maxtime = Inf)
tmp <- data.frame(i, tmp$times, tmp$states, 0)
names(tmp) <- c("id", "times", "state", "cost")
for(j in 1:nrow(tmp))
if(tmp$state[j] == 2) tmp$cost[j] <- rexp(1,rate = 1/cost)
xxx <- rbind(xxx,tmp)
}
xxx$surv <- ifelse(xxx$state > 2, xxx$times, 0)
xxx$delta <- ifelse(xxx$state == 3, 1, 0)
xxx$start <- xxx$times
xxx$stop <- NA
xxx$stop[-nrow(xxx)] <- ifelse(xxx$id[-nrow(xxx)] == xxx$id[-1], xxx$times[-1],NA)
sim <- xxx %>%
group_by(id) %>%
mutate(delta = max(delta),
surv = max(surv)) %>%
filter(state == 2) %>%
select(c("id", "start", "stop", "cost", "surv", "delta"))
sim$cost <- (sim$stop - sim$start) * sim$cost
simcost <- tapply(sim$cost, sim$id, sum)
return(list("totalCost" = simcost, "censoredCostHistory" = sim))
}
exact.cost <- function(lam, mu, gamma, delta){
# Function to calculate the exact cost in the illness-death model with recovery
f <- function(x, lam, mu, gamma, delta){
# formula
lam/(lam + mu)*(x + exp(-1*(lam+mu)*x)/(lam+mu) - 1/(lam+mu)) * (gamma*exp(-1*gamma*x)) * delta
#lam/(lam + mu)*(1-exp(-1*(lam+mu)*x)) * (gamma*exp(-1*gamma*x)) * delta
}
integrate(f, 0, Inf, lam, mu, gamma, delta)
}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(ccostr)
library(parallel)
library(msm)
library(dplyr)
library(survival)
library(knitr)
nSim   <- 1
nYears <- 10
## true mean for unif is 40000 and
## true mean for exp is 35956 (Bang & Tsiatis, 2000)
unif_light <- lapply(1:nSim, function(x) simCostData(dist = "unif", censor = "light", L=nYears))
unif_heavy <- lapply(1:nSim, function(x) simCostData(dist = "unif", censor = "heavy", L=nYears))
exp_light <- lapply(1:nSim, function(x) simCostData(dist = "exp", censor = "light", L=nYears))
exp_heavy <- lapply(1:nSim, function(x) simCostData(dist = "exp", censor = "heavy", L=nYears))
IDM_none <- lapply(1:nSim, function(x) sim.patients(n = 100, censor = 0, cost = 100))
IDM_light <- lapply(1:nSim, function(x) sim.patients(n = 100, censor = 0.05, cost = 100))
IDM_heavy <- lapply(1:nSim, function(x) sim.patients(n = 100, censor = 0.1, cost = 100))
### Estimate from censored data
nCores <- 1
cl <- makeCluster(nCores)
clusterExport(cl = cl, c("unif_light", "unif_heavy", "exp_light", "exp_heavy", "IDM_none", "IDM_light", "IDM_heavy"))
clusterEvalQ(cl = cl, {
library(dplyr)
library(ccostr)
library(survival)})
est_unif_light <- parLapply(cl, unif_light, function(x) ccmean(x$censoredCostHistory))
est_unif_heavy <- parLapply(cl, unif_heavy, function(x) ccmean(x$censoredCostHistory))
est_exp_light  <- parLapply(cl, exp_light, function(x) ccmean(x$censoredCostHistory))
est_exp_heavy  <- parLapply(cl, exp_heavy, function(x) ccmean(x$censoredCostHistory))
est_IDM_none   <- parLapply(cl, IDM_none, function(x) ccmean(x$censoredCostHistory))
est_IDM_light  <- parLapply(cl, IDM_light, function(x) ccmean(x$censoredCostHistory))
est_IDM_heavy  <- parLapply(cl, IDM_heavy, function(x) ccmean(x$censoredCostHistory))
stopCluster(cl)
## Summarize
results_unif_light <- do.call(rbind, lapply(est_unif_light, function(x) x[[2]]))
results_unif_heavy <- do.call(rbind, lapply(est_unif_heavy, function(x) x[[2]]))
results_exp_light  <- do.call(rbind, lapply(est_exp_light, function(x) x[[2]]))
results_exp_heavy  <- do.call(rbind, lapply(est_exp_heavy, function(x) x[[2]]))
results_IDM_none   <- do.call(rbind, lapply(est_IDM_none, function(x) x[[2]]))
results_IDM_light  <- do.call(rbind, lapply(est_IDM_light, function(x) x[[2]]))
results_IDM_heavy  <- do.call(rbind, lapply(est_IDM_heavy, function(x) x[[2]]))
results_true <- data.frame("unif_light" = 40000,
"unif_heavy" = 40000,
"exp_light"  = 35956,
"exp_heavy"  = 35956,
"IDM_none"   = exact.cost(0.2, 0.5, 0.1, 100)$value,
"IDM_light"  = exact.cost(0.2, 0.5, 0.1, 100)$value,
"IDM_heavy"  = exact.cost(0.2, 0.5, 0.1, 100)$value)
results_mean <- data.frame("unif_light" = mean(sapply(unif_light, function(x) mean(x$totalCost))),
"unif_heavy" = mean(sapply(unif_heavy, function(x) mean(x$totalCost))),
"exp_light"  = mean(sapply(exp_light, function(x) mean(x$totalCost))),
"exp_heavy"  = mean(sapply(exp_heavy, function(x) mean(x$totalCost))),
"IDM_none"   = NA,
"IDM_light"  = NA,
"IDM_heavy"  = NA)
results_bias <- data.frame("unif_light" = (colMeans(results_unif_light)),
"unif_heavy" = (colMeans(results_unif_heavy)),
"exp_light"  = (colMeans(results_exp_light)),
"exp_heavy"  = (colMeans(results_exp_heavy)),
"IDM_none"   = (colMeans(results_IDM_none)),
"IDM_light"  = (colMeans(results_IDM_light)),
"IDM_heavy"  = (colMeans(results_IDM_heavy)))
results <- rbind(results_true, results_mean, results_bias)
row.names(results) <- c("true_mean", "simulation_mean", colnames(results_unif_light))
kable(results)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-"
)
library(knitr)
id           <- c("A", "B" ,"C")
tcost        <- c(2544,4245,590)
delta        <- c(0,0,1)
surv         <- c(343,903,445)
df_0 <- data.frame(id, tcost, delta, surv)
kable(df_0)
id      <- c("A", "A", "A", "B" ,"C", "C")
start   <- c(1,30,88,18,1,67)
stop    <- c(1,82,88,198,5,88)
cost    <- c(550,1949,45,4245,23,567)
delta   <- c(0,0,0,0,1,1)
surv    <- c(343,343,343,903,445,445)
df_1 <- data.frame(id, start,stop,cost,delta,surv)
kable(df_1)
df_1_res <- ccmean(df_1, L = max(df_1$surv))
kable(df_1_res[[3]])
# Simulate data with the simCostData function
sim <- simCostData(n = 100, dist = "unif", censor = "heavy", L = 10)
# Apply ccmean and limit to 10 years (the true mean is 40.000 see documentation)
sim_res <- ccmean(sim[[2]], L = 10)
kable(sim_res[[3]])
devtools::install_github("HaemAalborg/ccostr")
# Or including a vignette that demonstrates the bias and coverage of
# the estimators, requires: library(parallel)
devtools::install_github("HaemAalborg/ccostr", build_vignettes = TRUE)
id           <- c("A", "B" ,"C")
tcost        <- c(2544,4245,590)
delta        <- c(0,0,1)
surv         <- c(343,903,445)
df_0 <- data.frame(id, tcost, delta, surv)
kable(df_0)
id      <- c("A", "A", "A", "B" ,"C", "C")
start   <- c(1,30,88,18,1,67)
stop    <- c(1,82,88,198,5,88)
cost    <- c(550,1949,45,4245,23,567)
delta   <- c(0,0,0,0,1,1)
surv    <- c(343,343,343,903,445,445)
df_1 <- data.frame(id, start,stop,cost,delta,surv)
kable(df_1)
library(ccostr)
df_1_res <- ccmean(df_1, L = max(df_1$surv))
kable(df_1_res[[3]])
# Simulate data with the simCostData function
sim <- simCostData(n = 100, dist = "unif", censor = "heavy", L = 10)
# Apply ccmean and limit to 10 years (the true mean is 40.000 see documentation)
sim_res <- ccmean(sim[[2]], L = 10)
kable(sim_res[[3]])
# Simulate data with the simCostData function
sim <- simCostData(n = 100, dist = "unif", censor = "heavy", L = 10)
# Apply ccmean and limit to 10 years (the true mean is 40.000 see documentation)
sim_res <- ccmean(sim[[2]], L = 10)
kable(sim_res[[3]])
View(ccmean)
View(ccmean)
devtools::install_github("HaemAalborg/ccostr")
devtools::install_github("HaemAalborg/ccostr")
install.packages(c("callr", "colorspace", "e1071", "fs", "ggfortify", "git2r", "highr", "kableExtra", "lazyeval", "msm", "pkgbuild", "readxl", "rmarkdown", "rstudioapi", "stringi", "tinytex"))
install.packages(c("fs", "ggfortify", "git2r"))
devtools::install_github("HaemAalborg/ccostr")
library(ccostr)
ccmean()
id           <- c("A", "B" ,"C")
tcost        <- c(2544,4245,590)
delta        <- c(0,0,1)
surv         <- c(343,903,445)
df_0 <- data.frame(id, tcost, delta, surv)
kable(df_0)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-"
)
library(knitr)
id           <- c("A", "B" ,"C")
tcost        <- c(2544,4245,590)
delta        <- c(0,0,1)
surv         <- c(343,903,445)
df_0 <- data.frame(id, tcost, delta, surv)
kable(df_0)
id      <- c("A", "A", "A", "B" ,"C", "C")
start   <- c(1,30,88,18,1,67)
stop    <- c(1,82,88,198,5,88)
cost    <- c(550,1949,45,4245,23,567)
delta   <- c(0,0,0,0,1,1)
surv    <- c(343,343,343,903,445,445)
df_1 <- data.frame(id, start,stop,cost,delta,surv)
kable(df_1)
View(ccmean)
library(ccostr)
df_1_res <- ccmean(df_1, L = max(df_1$surv))
kable(df_1_res[[3]])
# Simulate data with the simCostData function
sim <- simCostData(n = 100, dist = "unif", censor = "heavy", L = 10)
# Apply ccmean and limit to 10 years (the true mean is 40.000 see documentation)
sim_res <- ccmean(sim[[2]], L = 10)
kable(sim_res[[3]])
df_1_res <- ccmean(df_1, L = max(df_1$surv),delta = delta)
kable(df_1_res[[3]])
df_1_res <- ccmean(df_1, L = max(df_1$surv),delta = df1$delta)
kable(df_1_res[[3]])
df_1_res <- ccmean(df_1)
kable(df_1_res[[3]])
x <- df_1
x
L <- max(x$surv)
# Subset to estimation period
x$delta[x$surv >= L] <- 1
x
x$surv <- pmin(x$surv, L)
x
x <- subset(x, start <= L)
x
# Adjust overlapping costs
x$cost <- ifelse(x$stop > x$surv, x$cost * ((x$surv-x$start + addInterPol)/(x$stop-x$start + addInterPol)), x$cost)
x
x$stop <- pmin(x$stop, L)
x
df_1
# Ordering the dataset
x <- x[order(x$surv, x$delta),]
row.names(x) <- 1:nrow(x)
# Some calculations don't use cost history and therefore collapse by ID
xf <- x %>%
group_by(id) %>%
summarize(cost = sum(cost, na.rm=T),
delta = last(delta),
surv = first(surv))
x
xf
mean(xf$cost)
mean(xf$cost[xf$delta==1])
x <- df_1
L <- max(x$surv)
# Subset to estimation period
x$delta[x$surv > L] <- 1
x$surv <- pmin(x$surv, L)
x <- subset(x, start <= L)
# Adjust overlapping costs
x$cost <- ifelse(x$stop > x$surv, x$cost * ((x$surv-x$start + addInterPol)/(x$stop-x$start + addInterPol)), x$cost)
x$stop <- pmin(x$stop, L)
# Ordering the dataset
x <- x[order(x$surv, x$delta),]
row.names(x) <- 1:nrow(x)
# Some calculations don't use cost history and therefore collapse by ID
xf <- x %>%
group_by(id) %>%
summarize(cost = sum(cost, na.rm=T),
delta = last(delta),
surv = first(surv))
#################################################################
##                          section 1:                         ##
##                   Naive (Avaiable Sample)                   ##
#################################################################
# Costs are summed and a mean are found
available_sample <- mean(xf$cost)
available_sample_full <- c(available_sample, NA, NA, NA, NA)
#################################################################
##                          section 2:                         ##
##                    Naive (complete case)                    ##
#################################################################
# Costs are summed up and calculated mean
complete_case <- mean(xf$cost[xf$delta==1])
complete_case_full <- c(complete_case, NA, NA, NA, NA)
mean(xf$cost)
mean(xf$cost[xf$delta==1])
devtools::install_github("HaemAalborg/ccostr")
id      <- c("A", "A", "A", "B" ,"C", "C")
start   <- c(1,30,88,18,1,67)
stop    <- c(1,82,88,198,5,88)
cost    <- c(550,1949,45,4245,23,567)
delta   <- c(0,0,0,0,1,1)
surv    <- c(343,343,343,903,445,445)
df_1 <- data.frame(id, start,stop,cost,delta,surv)
kable(df_1)
library(ccostr)
df_1_res <- ccmean(df_1)
kable(df_1_res[[3]])
View(ccmean)
remove.packages("ccostr", lib="~/R/win-library/3.4")
devtools::install_github("HaemAalborg/ccostr")
library("ccostr", lib.loc="~/R/win-library/3.4")
View(annCost)
View(ccmean)
View(ccmean)
setwd("~/GitHub")
devtools::build(path = "ccostr")
devtools::build(path = "/ccostr")
devtools::build(path = "/ccostr")
devtools::build(path = "/ccostr/")
devtools::build(path = "ccostr/")
devtools::build(path = "ccostr/DESCRIPTION")
setwd("~/GitHub/ccostr")
devtools::build(path = "")
devtools::document()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-"
)
library(knitr)
devtools::install_github("HaemAalborg/ccostr")
library(ccostr)
View(ccmean)
View(ccmean)
View(ccmean)
View(ccmean)
View(ccmean)
